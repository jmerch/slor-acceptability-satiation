general:
    model_name:
    run_name: polar_10_firstrun
    output_dir: /checkpoints
    wandb_project: gpt2-satiation
training:
    learning_rate: 1.0e-03 # experiment with this; default is 5e-5
    per_device_train_batch_size: 1
    per_device_eval_batch_size: 1
    num_train_epochs: 20
    report_to: wandb
    save_steps: 50
    save_strategy: steps
    remove_unused_columns: false
    evaluation_strategy: epoch
