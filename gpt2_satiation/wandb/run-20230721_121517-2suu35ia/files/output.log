The following columns in the training set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.
/Users/lianwang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 0
  Num Epochs = 3
  Instantaneous batch size per device = 1
  Total train batch size (w. parallel, distributed & accumulation) = 1
  Gradient Accumulation steps = 1
  Total optimization steps = 30
  0%|                                                                                     | 0/30 [00:00<?, ?it/s]Traceback (most recent call last):
  File "satiation.py", line 51, in <module>
    trainer.train()
  File "/Users/lianwang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/trainer.py", line 1396, in train
    for step, inputs in enumerate(epoch_iterator):
  File "/Users/lianwang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/Users/lianwang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/Users/lianwang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 56, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
  File "/Users/lianwang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2796, in __getitems__
    batch = self.__getitem__(keys)
  File "/Users/lianwang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2792, in __getitem__
    return self._getitem(key)
  File "/Users/lianwang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2776, in _getitem
    pa_subtable = query_table(self._data, key, indices=self._indices if self._indices is not None else None)
  File "/Users/lianwang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 583, in query_table
    _check_valid_index_key(key, size)
  File "/Users/lianwang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 536, in _check_valid_index_key
    _check_valid_index_key(int(max(key)), size=size)
  File "/Users/lianwang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 526, in _check_valid_index_key
    raise IndexError(f"Invalid key: {key} is out of bounds for size {size}")
IndexError: Invalid key: 8 is out of bounds for size 0